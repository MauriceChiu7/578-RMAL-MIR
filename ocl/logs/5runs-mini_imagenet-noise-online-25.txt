Namespace(num_runs=5, seed=0, val_size=0.1, num_val=3, num_runs_val=3, error_analysis=True, verbose=True, store=False, save_path=None, agent='ER', update='random', retrieve='MIR', optimizer='SGD', learning_rate=0.1, epoch=1, batch=10, test_batch=128, weight_decay=0, num_tasks=10, fix_order=False, plot_sample=False, data='mini_imagenet', cl_type='ni', ns_factor=[0.0, 0.4, 0.8, 1.2, 1.6, 2.0, 2.4, 2.8, 3.2, 3.6], ns_type='noise', ns_task=(1, 1, 2, 2, 2, 2), online=True, mem_size=5000, eps_mem_batch=10, lambda_=100, alpha=0.9, fisher_update_after=50, subsample=50, gss_mem_strength=10, gss_batch_size=10, k=5, aser_type='asvm', n_smp_cls=2.0, stm_capacity=1000, classifier_chill=0.01, log_alpha=-300, minlr=0.0005, clip=10.0, mem_epoch=70, labels_trick=False, separated_softmax=False, kd_trick=False, kd_trick_star=False, review_trick=False, ncm_trick=False, mem_iters=1, min_delta=0.0, patience=0, cumulative_delta=False, temp=0.07, buffer_tracker=False, warmup=4, head='mlp', budget=0.25, cuda=True)
Setting up data stream
data setup time: 3.0302059650421143
0 0.0
1 0.4
2 0.8
3 1.2
4 1.6
5 2.0
6 2.4
7 2.8
8 3.2
9 3.6
buffer has 5000 slots
-----------run 0 training batch 0-------------
size: (4500, 84, 84, 3), (4500,)
==>>> it: 1, avg. loss: 6.366927, running train acc: 0.000
==>>> it: 1, mem avg. loss: 2.513958, running mem acc: 0.100
[0.009 0.011 0.01  0.015 0.009 0.017 0.008 0.009 0.011 0.008]
no ratio: 0.0
on ratio: 0.0
[(0, 991, 0, 0)]
[-0.02334323337674141]
[0]
[nan]
[-7.530926814069971e-05]
[nan]
[-0.001238350523635745]
-----------run 0 training batch 1-------------
size: (4500, 84, 84, 3), (4500,)
==>>> it: 1, avg. loss: 5.725953, running train acc: 0.000
==>>> it: 1, mem avg. loss: 2.122943, running mem acc: 0.550
[0.013 0.016 0.016 0.016 0.022 0.017 0.015 0.012 0.017 0.02 ]
no ratio: 0.0
on ratio: 0.9998986931415257
[(0, 991, 0, 0), (0, 984, 0, 987)]
[-0.02334323337674141, -0.03905413690209389]
[0, nan]
[nan, nan]
[-7.530926814069971e-05, -7.530929724453017e-05]
[nan, nan]
[-0.001238350523635745, -0.0012383506400510669]
-----------run 0 training batch 2-------------
size: (4500, 84, 84, 3), (4500,)
==>>> it: 1, avg. loss: 5.523331, running train acc: 0.000
==>>> it: 1, mem avg. loss: 2.519404, running mem acc: 0.250
[0.009 0.012 0.009 0.012 0.016 0.018 0.007 0.011 0.014 0.009]
no ratio: 0.0
on ratio: 0.9999494719822142
[(0, 991, 0, 0), (0, 984, 0, 987), (0, 991, 0, 1979)]
[-0.02334323337674141, -0.03905413690209389, -0.005985401742160321]
[0, nan, nan]
[nan, nan, nan]
[-7.530926814069971e-05, -7.530929724453017e-05, -7.53093117964454e-05]
[nan, nan, nan]
[-0.001238350523635745, -0.0012383506400510669, -0.0012383508728817105]
-----------run 0 training batch 3-------------
size: (4500, 84, 84, 3), (4500,)
==>>> it: 1, avg. loss: 6.167481, running train acc: 0.000
==>>> it: 1, mem avg. loss: 2.695930, running mem acc: 0.300
[0.01  0.016 0.01  0.012 0.017 0.019 0.009 0.012 0.013 0.011]
no ratio: 0.0
on ratio: 0.9999662629465943
[(0, 991, 0, 0), (0, 984, 0, 987), (0, 991, 0, 1979), (0, 988, 0, 2964)]
[-0.02334323337674141, -0.03905413690209389, -0.005985401742160321, -0.008337552703917027]
[0, nan, nan, nan]
[nan, nan, nan, nan]
[-7.530926814069971e-05, -7.530929724453017e-05, -7.53093117964454e-05, -7.530943548772484e-05]
[nan, nan, nan, nan]
[-0.001238350523635745, -0.0012383506400510669, -0.0012383508728817105, -0.0012383514549583197]
-----------run 0 training batch 4-------------
size: (4500, 84, 84, 3), (4500,)
==>>> it: 1, avg. loss: 5.205442, running train acc: 0.000
==>>> it: 1, mem avg. loss: 3.343518, running mem acc: 0.100
[0.01  0.017 0.015 0.012 0.013 0.018 0.011 0.019 0.009 0.008]
no ratio: 0.0
on ratio: 0.9999746585236056
[(0, 991, 0, 0), (0, 984, 0, 987), (0, 991, 0, 1979), (0, 988, 0, 2964), (0, 987, 0, 3946)]
[-0.02334323337674141, -0.03905413690209389, -0.005985401742160321, -0.008337552703917027, -0.012134575270116328]
[0, nan, nan, nan, nan]
[nan, nan, nan, nan, nan]
[-7.530926814069971e-05, -7.530929724453017e-05, -7.53093117964454e-05, -7.530943548772484e-05, -7.530942821176723e-05]
[nan, nan, nan, nan, nan]
[-0.001238350523635745, -0.0012383506400510669, -0.0012383508728817105, -0.0012383514549583197, -0.0012383514549583197]
-----------run 0 training batch 5-------------
size: (4500, 84, 84, 3), (4500,)
==>>> it: 1, avg. loss: 4.925653, running train acc: 0.100
==>>> it: 1, mem avg. loss: 3.260471, running mem acc: 0.200
[0.007 0.018 0.01  0.009 0.006 0.011 0.015 0.007 0.012 0.005]
no ratio: 0.0
on ratio: 0.9999797983879113
[(0, 991, 0, 0), (0, 984, 0, 987), (0, 991, 0, 1979), (0, 988, 0, 2964), (0, 987, 0, 3946), (0, 989, 0, 4950)]
[-0.02334323337674141, -0.03905413690209389, -0.005985401742160321, -0.008337552703917027, -0.012134575270116328, 0.16928542268276214]
[0, nan, nan, nan, nan, nan]
[nan, nan, nan, nan, nan, nan]
[-7.530926814069971e-05, -7.530929724453017e-05, -7.53093117964454e-05, -7.530943548772484e-05, -7.530942821176723e-05, -7.530947186751291e-05]
[nan, nan, nan, nan, nan, nan]
[-0.001238350523635745, -0.0012383506400510669, -0.0012383508728817105, -0.0012383514549583197, -0.0012383514549583197, -0.0012383514549583197]
-----------run 0 training batch 6-------------
size: (4500, 84, 84, 3), (4500,)
==>>> it: 1, avg. loss: 4.422665, running train acc: 0.050
==>>> it: 1, mem avg. loss: 4.375006, running mem acc: 0.050
[0.022 0.022 0.022 0.028 0.025 0.023 0.018 0.024 0.021 0.03 ]
no ratio: 0.0
on ratio: 0.9999829296188183
[(0, 991, 0, 0), (0, 984, 0, 987), (0, 991, 0, 1979), (0, 988, 0, 2964), (0, 987, 0, 3946), (0, 989, 0, 4950), (0, 982, 0, 5858)]
[-0.02334323337674141, -0.03905413690209389, -0.005985401742160321, -0.008337552703917027, -0.012134575270116328, 0.16928542268276214, -0.007167766790837049]
[0, nan, nan, nan, nan, nan, nan]
[nan, nan, nan, nan, nan, nan, nan]
[-7.530926814069971e-05, -7.530929724453017e-05, -7.53093117964454e-05, -7.530943548772484e-05, -7.530942821176723e-05, -7.530947186751291e-05, -7.530953735113144e-05]
[nan, nan, nan, nan, nan, nan, nan]
[-0.001238350523635745, -0.0012383506400510669, -0.0012383508728817105, -0.0012383514549583197, -0.0012383514549583197, -0.0012383514549583197, -0.0012383516877889633]
-----------run 0 training batch 7-------------
size: (4500, 84, 84, 3), (4500,)
==>>> it: 1, avg. loss: 4.546732, running train acc: 0.050
==>>> it: 1, mem avg. loss: 3.694364, running mem acc: 0.150
[0.016 0.023 0.017 0.016 0.025 0.029 0.019 0.02  0.018 0.022]
no ratio: 0.0
on ratio: 0.9999854123207539
[(0, 991, 0, 0), (0, 984, 0, 987), (0, 991, 0, 1979), (0, 988, 0, 2964), (0, 987, 0, 3946), (0, 989, 0, 4950), (0, 982, 0, 5858), (0, 980, 0, 6855)]
[-0.02334323337674141, -0.03905413690209389, -0.005985401742160321, -0.008337552703917027, -0.012134575270116328, 0.16928542268276214, -0.007167766790837049, -0.021293604522943498]
[0, nan, nan, nan, nan, nan, nan, nan]
[nan, nan, nan, nan, nan, nan, nan, nan]
[-7.530926814069971e-05, -7.530929724453017e-05, -7.53093117964454e-05, -7.530943548772484e-05, -7.530942821176723e-05, -7.530947186751291e-05, -7.530953735113144e-05, -7.530959555879235e-05]
[nan, nan, nan, nan, nan, nan, nan, nan]
[-0.001238350523635745, -0.0012383506400510669, -0.0012383508728817105, -0.0012383514549583197, -0.0012383514549583197, -0.0012383514549583197, -0.0012383516877889633, -0.001238351920619607]
-----------run 0 training batch 8-------------
size: (4500, 84, 84, 3), (4500,)
==>>> it: 1, avg. loss: 4.854026, running train acc: 0.000
==>>> it: 1, mem avg. loss: 3.194403, running mem acc: 0.100
